# Convert to lowercase and tokenize
tokens <- tokens(keyword_vector, what = "word", remove_punct = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("en")) %>%
tokens_wordstem() # Stemming words
# Create bi-grams
bigrams <- tokens_ngrams(tokens, n = 2, concatenator = "_")
# Convert tokens back to strings
bigrams_strings <- sapply(bigrams, function(bigram) {
paste(bigram, collapse = " ")
})
return(bigrams_strings)
}
# Apply the function to each vector in the list
new_keywords_bigrams <- lapply(new_keywords, preprocess_and_create_bigrams)
# Print result
print(new_keywords_bigrams)
# Function to preprocess keywords: lowercase, remove stopwords, stem, and split into words
preprocess_keywords <- function(keywords_list) {
lapply(keywords_list, function(vec) {
unlist(lapply(vec, function(keyword) {
tokens <- tokens(keyword, what = "word", remove_punct = TRUE) %>%  # Tokenize
tokens_tolower() %>%                                      # Convert to lowercase
tokens_remove(stopwords("en")) %>%                        # Remove stopwords
tokens_wordstem()                                         # Stem words
paste(tokens, collapse=" ")
}))
})
}
# Apply the preprocessing function to the list
preprocessed_keywords <- preprocess_keywords(new_keywords)
# old keywords
old_keywords_with_war = list(cultural = c('histor','tear','demolish','commemor',
'center','museum','heritag','council',
'street','demolit','cultur'),
economic = c('wage','system','econom','compani',
'nationwid','annual','anti-capitalist',
'fairer','paid','promis','pay','land',
'health','increas','bonus',
'payment','left','work'),
environmental = c('park','wast','zone',
'forest','green','road','tree',
'expans','villag','block','cut',
'ecolog','pollut'),
legal = c('amend','term','constitut','propos',
'presidenti','extend',
'limit','law'),
political = c('arrest','releas','governor',
'polit','sentenc',
'assassin','attempt','administr',
'fsb','ldpr','jail','murder','motiv',
'journalist','involv','denounc','critic'),
social = c('vaccin','public','space','certif',
'shop','restaur','mall','mandatori',
'farm','school','interest'),
war = c('ukrain', 'war', 'invas', 'invad', 'militari', 'annex'))
# Function to join two vectors
join_vectors <- function(vec1, vec2) {
paste0(vec1, ", ", vec2)
}
# Creating the combined list
keywords_combined_list <- Map(join_vectors, old_keywords_with_war, preprocessed_keywords)
View(keywords_combined_list)
keywords_combined_list[["cultural"]]
# Function to combine elements of two vectors
combine_vectors <- function(vec1, vec2) {
c(vec1, vec2)
}
# Creating the combined list
combined_list <- Map(combine_vectors, old_keywords_with_war, preprocessed_keywords)
combined_list
out <- keyATM(
docs              = keyATM_docs,    # text input
no_keyword_topics = 1,              # number of topics without keyword
keywords          = combined_list,       # keywords
model             = "base",         # select the model
options           = list(seed = 250)
)
save(out, file = "acled_keyatm_base_1901.RData")
## diagnostics
plot_topicprop(out, show_topic = 1:7)
fig_modelfit <- plot_modelfit(out)
fig_modelfit
plot_alpha(out)
plot_pi(out)
##### get protest type based on topic probs ####
acled_with_types = out$theta %>%
as.data.frame() %>%
cbind(acled) %>%
pivot_longer(cols = `1_cultural`:`Other_1`, names_to = "topic", values_to = "proportion") %>%
group_by(event_id_cnty) %>%
mutate(max = proportion == max(proportion)) %>%
filter(max) %>%
mutate(protest_type = case_when(
topic == "Other_1" ~ "unclear",
TRUE ~ str_extract(topic, "(?<=_).+")) %>%
factor(levels = c('environmental', 'cultural',
'political', 'social',
'economic', 'legal',
'war', 'unclear')))
##### get protest type based on topic probs ####
acled_with_types = out$theta %>%
as.data.frame() %>%
out$theta %>%
as.data.frame()
acled_with_types = out$theta %>%
as.data.frame()
View(acled_with_types)
acled_with_types = out$theta %>%
as.data.frame() %>%
cbind(acled)
View(acled_with_types)
##### load and preprocess data #####
acled <- import("data/processed_data/acled_main_with_manual_coding_2018_2023.csv")
View(acled)
acled_subset <- acled %>%
select(-c(topic, proportion, max))
View(acled_subset)
acled_subset <- acled %>%
select(-c(topic, proportion, max, protest_type))
##### get protest type based on topic probs ####
acled_with_types = out$theta %>%
as.data.frame() %>%
cbind(acled_subset) %>%
pivot_longer(cols = `1_cultural`:`Other_1`, names_to = "topic", values_to = "proportion") %>%
group_by(event_id_cnty) %>%
mutate(max = proportion == max(proportion)) %>%
filter(max) %>%
mutate(protest_type = case_when(
topic == "Other_1" ~ "unclear",
TRUE ~ str_extract(topic, "(?<=_).+")) %>%
factor(levels = c('environmental', 'cultural',
'political', 'social',
'economic', 'legal',
'war', 'unclear')))
View(acled_with_types)
new_subset_with_manual <- acled_with_types %>%
filter(!is.na(topic_manual))
new_subset <- acled_with_types %>%
filter(!is.na(topic_manual))
unique(new_subset$topic_manual)
unique(new_subset$protest_type)
new_subset <- acled_with_types %>%
filter(!is.na(topic_manual)) %>%
mutate(protest_manual = case_when(
topic_manual %in% c("war (pro)", "war (anti)") ~ "war",
TRUE ~ topic_manual
))
View(new_subset)
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$protest_manual <- as.factor(new_subset$protest_manual)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$protest_manual)
new_subset <- acled_with_types %>%
filter(!is.na(topic_manual),
protest_type != "unclear") %>%
mutate(protest_manual = case_when(
topic_manual %in% c("war (pro)", "war (anti)") ~ "war",
TRUE ~ topic_manual
))
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$protest_manual <- as.factor(new_subset$protest_manual)
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$protest_manual)
levels(new_subset$protest_type)
new_subset <- acled_with_types %>%
filter(!is.na(topic_manual),
protest_type != "unclear") %>%
mutate(protest_manual = case_when(
topic_manual %in% c("war (pro)", "war (anti)") ~ "war",
TRUE ~ topic_manual
))
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$protest_manual <- as.factor(new_subset$protest_manual)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$protest_manual)
levels(new_subset$protest_type)
new_subset <- acled_with_types %>%
filter(!is.na(topic_manual) &
protest_type != "unclear") %>%
mutate(protest_manual = case_when(
topic_manual %in% c("war (pro)", "war (anti)") ~ "war",
TRUE ~ topic_manual
))
levels(new_subset$protest_type)
unique(new_subset$protest_type)
new_subset <- acled_with_types %>%
filter(!is.na(topic_manual) &
protest_type != "unclear") %>%
mutate(protest_manual = case_when(
topic_manual %in% c("war (pro)", "war (anti)") ~ "war",
TRUE ~ topic_manual
))
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$protest_manual <- as.factor(new_subset$protest_manual)
levels(new_subset$protest_type)
unique(new_subset$protest_type)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$protest_manual)
out <- keyATM(
docs              = keyATM_docs,    # text input
no_keyword_topics = 0,              # number of topics without keyword
keywords          = combined_list,       # keywords
model             = "base",         # select the model
options           = list(seed = 250)
)
save(out, file = "acled_keyatm_base_no_other_1901.RData")
fig_modelfit <- plot_modelfit(out)
fig_modelfit
acled_subset <- acled %>%
select(-c(topic, proportion, max, protest_type))
acled_with_types = out$theta %>%
as.data.frame() %>%
cbind(acled_subset)
View(acled_with_types)
acled_with_types = out$theta %>%
as.data.frame() %>%
cbind(acled_subset) %>%
pivot_longer(cols = `1_cultural`:`7_war`, names_to = "topic", values_to = "proportion") %>%
group_by(event_id_cnty) %>%
mutate(max = proportion == max(proportion)) %>%
filter(max) %>%
mutate(protest_type = str_extract(topic, "(?<=_).+")) %>%
mutate(protest_type = factor(protest_type, levels = c('environmental', 'cultural',
'political', 'social',
'economic', 'legal',
'war')))
new_subset <- acled_with_types %>%
filter(!is.na(topic_manual)) %>%
mutate(protest_manual = case_when(
topic_manual %in% c("war (pro)", "war (anti)") ~ "war",
TRUE ~ topic_manual
))
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$protest_manual <- as.factor(new_subset$protest_manual)
levels(new_subset$protest_type)
unique(new_subset$protest_type)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$protest_manual)
print(conf_matrix)
# Accuracy
accuracy <- conf_matrix$overall['Accuracy']
print(paste("Accuracy:", accuracy))
# Precision, Recall, and F1-Score
precision <- posPredValue(new_subset$protest_type, new_subset$protest_manual, positive="Specific Class")
# Accuracy
accuracy <- conf_matrix$overall['Accuracy']
print(paste("Accuracy:", accuracy))
# Precision, Recall, and F1-Score
precision <- posPredValue(new_subset$protest_type, new_subset$protest_manual, positive="Specific Class")
# Precision, Recall, and F1-Score
precision <- posPredValue(new_subset$protest_type, new_subset$protest_manual, positive="political")
precision <- posPredValue(new_subset$protest_type, new_subset$protest_manual, positive="political")
recall <- sensitivity(new_subset$protest_type, new_subset$protest_manual, positive="economic")
# Precision, Recall, and F1-Score
precision <- posPredValue(new_subset$protest_type, new_subset$protest_manual, positive="economic")
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$protest_manual)
print(conf_matrix)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$protest_manual)
print(conf_matrix)
new_subset <- acled_with_types %>%
filter(!is.na(topic_manual)) %>%
mutate(protest_manual = case_when(
topic_manual %in% c("war (pro)", "war (anti)") ~ "war",
TRUE ~ topic_manual
))
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$protest_manual <- as.factor(new_subset$protest_manual)
levels(new_subset$protest_type)
unique(new_subset$protest_type)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$protest_manual)
print(conf_matrix)
View(new_subset)
acled_2018_2023 <- import("data/processed_data/acled_types_auth_2018_2023.csv")
acled_2018_2023 <- import("data/processed_data/acled_types_auth_2018_2023.csv")
acled <- import("data/processed_data/acled_protest_krml_indicator.csv")
## set up
acled_2018_2023 <- import("data/processed_data/acled_types_auth_2018_2023.csv")
View(acled_2018_2023)
# Convert date column to Date object and create month-year object
acled <- acled %>%
mutate(date = dmy(event_date),
month_year = format(date, "%Y-%m"))
acled_2018_2023 <- import("data/processed_data/acled_types_auth_2018_2023.csv")
# Convert date column to Date object and create month-year object
acled <- acled %>%
mutate(date = dmy(event_date),
month_year = format(date, "%Y-%m"))
?sample_n
## set up
acled_2018_2023 <- import("data/processed_data/acled_types_auth_2018_2023.csv")
# Convert date column to Date object and create month-year object
acled_2018_2023 <- acled_2018_2023 %>%
mutate(date = dmy(event_date),
month_year = format(date, "%Y-%m"))
# Filter for the years 2018, 2019, 2020, 2021, 2023
filtered_data <- acled_2018_2023 %>%
filter(year %in% c(2018, 2019, 2020, 2021, 2023))
# Stratified sampling
set.seed(123)
sampled_data <- filtered_data %>%
group_by(year) %>%
do({
# For each year, calculate sample size per month
months_available <- length(unique(.$month))
sample_size <- ceiling(100 / months_available)
# Sample within each year
.$ %>%
# Stratified sampling
set.seed(123)
sampled_data <- filtered_data %>%
group_by(year) %>%
do({
# For each year, calculate sample size per month
months_available <- length(unique(.$month))
sample_size <- ceiling(100 / months_available)
# Sample within each year
.$ %>%
# Stratified sampling
set.seed(123)
sampled_data <- filtered_data %>%
group_by(year) %>%
do({
# For each year, calculate sample size per month
months_available <- length(unique(.$month))
sample_size <- ceiling(100 / months_available)
# Sample within each year
. %>%
group_by(month) %>%
sample_n(size = min(n(), sample_size), replace = FALSE)
}) %>%
ungroup()
filtered_data %>%
group_by(year)
# Convert date column to Date object and create month-year object
acled_2018_2023 <- acled_2018_2023 %>%
mutate(date = dmy(event_date),
year = year(date),
month = month(date))
# Filter for the years 2018, 2019, 2020, 2021, 2023
filtered_data <- acled_2018_2023 %>%
filter(year %in% c(2018, 2019, 2020, 2021, 2023))
acled_2018_2023 <- import("data/processed_data/acled_types_auth_2018_2023.csv")
# Convert date column to Date object and create month-year object
acled_2018_2023 <- acled_2018_2023 %>%
mutate(date = dmy(event_date),
year = year(date),
month = month(date))
# Filter for the years 2018, 2019, 2020, 2021, 2023
filtered_data <- acled_2018_2023 %>%
filter(year %in% c(2018, 2019, 2020, 2021, 2023))
sampled_data <- filtered_data %>%
group_by(year, month) %>%
summarise(n = n()) %>%
mutate(sample_size = ceiling(100 / length(unique(month)))) %>%
rowwise() %>%
mutate(sampled = list(filtered_data %>%
filter(year == year, month == month) %>%
slice_sample(n = min(sample_size, n)))) %>%
ungroup() %>%
select(-n, -sample_size) %>%
unnest(sampled)
# Stratified sampling
set.seed(123) # for reproducibility
sampled_data <- filtered_data %>%
group_by(year, month) %>%
summarise(n = n()) %>%
mutate(sample_size = ceiling(100 / length(unique(month)))) %>%
rowwise() %>%
mutate(sampled = list(filtered_data %>%
filter(year == year, month == month) %>%
slice_sample(n = min(sample_size, n)))) %>%
ungroup() %>%
select(-n, -sample_size) %>%
unnest(sampled)
filtered_data %>%
group_by(year, month) %>%
summarise(n = n()) %>%
mutate(sample_size = ceiling(100 / length(unique(month))))
filtered_data %>%
group_by(year, month) %>%
summarise(n = n()) %>%
mutate(sample_size = ceiling(100 / length(unique(month)))) %>%
rowwise() %>%
mutate(sampled = list(filtered_data %>%
filter(year == year, month == month) %>%
slice_sample(n = min(sample_size, n)))) %>%
ungroup()
sampled_data <- filtered_data %>%
group_by(year, month) %>%
summarise(n = n()) %>%
mutate(sample_size = ceiling(100 / length(unique(month)))) %>%
rowwise() %>%
mutate(sampled = list(filtered_data %>%
filter(year == year, month == month) %>%
slice_sample(n = min(sample_size, n)))) %>%
ungroup() %>%
select(-n, -sample_size) %>%
unnest(sampled)
# Stratified sampling
set.seed(123)  # for reproducibility
sampled_data <- filtered_data %>%
group_by(year, month) %>%
summarise(n = n(), .groups = 'drop') %>%
mutate(sample_size = ceiling(100 / length(unique(filtered_data$month)))) %>%
left_join(filtered_data, by = c("year", "month")) %>%
group_by(year, month) %>%
slice_sample(n = min(sample_size, n), replace = TRUE) %>%
ungroup()
# Calculate sample size for each year
sample_sizes <- filtered_data %>%
group_by(year) %>%
summarise(months = n_distinct(month)) %>%
mutate(sample_size = ceiling(100 / months)) %>%
select(-months)
# Perform stratified sampling
set.seed(123)  # for reproducibility
sampled_data <- filtered_data %>%
left_join(sample_sizes, by = "year") %>%
group_by(year, month) %>%
slice_sample(n = min(n(), sample_size), replace = TRUE) %>%
ungroup()
# Define a function to sample for each year-month combination
sample_for_group <- function(year, month, data, total_sample_size) {
sample_size_per_month <- ceiling(total_sample_size / 12)
group_data <- data %>%
filter(year == year, month == month)
group_sample <- group_data %>%
slice_sample(n = min(n(), sample_size_per_month), replace = TRUE)
return(group_sample)
}
# Perform stratified sampling
set.seed(123)  # for reproducibility
sampled_data <- map_dfr(year_month_combinations, ~sample_for_group(.x$year, .x$month, filtered_data, 100))
# Create a list of all year-month combinations
year_month_combinations <- filtered_data %>%
distinct(year, month)
# Define a function to sample for each year-month combination
sample_for_group <- function(year, month, data, total_sample_size) {
sample_size_per_month <- ceiling(total_sample_size / 12)
group_data <- data %>%
filter(year == year, month == month)
group_sample <- group_data %>%
slice_sample(n = min(n(), sample_size_per_month), replace = TRUE)
return(group_sample)
}
# Perform stratified sampling
set.seed(123)  # for reproducibility
sampled_data <- map_dfr(year_month_combinations, ~sample_for_group(.x$year, .x$month, filtered_data, 100))
acled_2018_2023 <- import("data/processed_data/acled_types_auth_2018_2023.csv")
View(acled_2018_2023)
pacman::p_load(tidyverse, rio, ggplot2, lubridate, quanteda, keyATM, readxl, caret)
acled <- import("data/processed_data/acled_protest_krml_indicator.csv")
# %>%
#   mutate(docid = paste("text", row_number(), sep = ""))
corp_acled = corpus(acled, text_field = "notes",
docid_field = "event_id_cnty")
# tokenize texts (copying code from acled_keyatm.R)
toks_acled = tokens(corp_acled, remove_punct = TRUE, remove_number = TRUE) %>%
tokens_remove(pattern = c(stopwords("en"), "protest*", "size", "=")) %>%
tokens_wordstem() # stem the keywords to make it easier to use later
dfmt_acled = dfm(toks_acled) %>%
dfm_trim(max_termfreq = 0.80, termfreq_type = "prop") #filter out most common words
keyATM_docs <- keyATM_read(texts = dfmt_acled)
summary(keyATM_docs)
# save(out, file = "acled_keyatm_base_2711.RData")
load("outputs/acled_keyatm_base_2711.RData")
##### get protest type based on topic probs ####
acled_with_types = out$theta %>%
as.data.frame() %>%
cbind(acled) %>%
pivot_longer(cols = `1_cultural`:`Other_1`, names_to = "topic", values_to = "proportion") %>%
group_by(event_id_cnty) %>%
mutate(max = proportion == max(proportion)) %>%
filter(max) %>%
mutate(protest_type = case_when(
topic == "Other_1" ~ "unclear",
TRUE ~ str_extract(topic, "(?<=_).+")) %>%
factor(levels = c('environmental', 'cultural',
'political', 'social',
'economic', 'legal',
'war', 'unclear')))
##### (un)authorised indicator #####
#dictionary
dict = quanteda::dictionary(list(unauthorized = c("not authorized", "unauthorized", "unlawful",
"unsanctioned", "did not approve",
"did not authorize", "not sanctioned",
"not been authorized"),
authorized = c("was authorized", "an authorized",
"was approved", "was sanctioned",
"authorized protest*")))
# alternative tokens with no pre-processing
# as compared to stemmed acled tokens used for keyATM
acled_toks = tokens(corp_acled)
dict_toks = tokens_lookup(acled_toks, dictionary = dict)
res = convert(dfm(dict_toks), to = "data.frame") %>%
rename(event_id_cnty = doc_id)
# check for the indicator
non_zero_count = sum(res$unauthorized != 0 & res$authorized != 0)
# there are 7 observations non-zero values for both auth and non-auth indicator
non_zero_observations <- res %>%
filter(unauthorized != 0 & authorized != 0)
# merge
acled_res = acled_with_types %>% left_join(res, by = "event_id_cnty")
acled_res = acled_with_types %>% left_join(res, by = "event_id_cnty") %>%
mutate(date = dmy(event_date),
year = year(date),
month = month(date))
View(acled_res)
write_csv(acled_res, "data/processed_data/acled_types_auth_2018_2023.csv")
