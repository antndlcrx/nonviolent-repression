deframe() %>% # Converts the dataframe to a named list
map(~ unlist(.x)) # To ensure each element is a vector of words rather than a list
keyATM_docs <- keyATM_read(texts = dfmt_acled)
summary(keyATM_docs)
##### fit new key atm ####
# #generate testing data
# set.seed(123)
# test_ids = acled_with_type %>%
#   group_by(topic_manual) %>%
#   sample_frac(0.3) %>%
#   pull(event_id_cnty)
#
#
# #generate labels (with NAs for testing data)
# acled_with_labels = acled %>%
#   left_join(acled_with_type %>% select(event_id_cnty, topic_manual)) %>%
#   mutate(label = as.factor(ifelse(event_id_cnty %in% test_ids, NA, topic_manual))
#          %>% as.numeric())
# labels_use = acled_with_labels$label
# Fit keyatm with labels
out <- keyATM(
docs              = keyATM_docs,    # text input
no_keyword_topics = 0,              # number of topics without keyword
keywords          = keywords,       # keywords
model             = "base",         # select the model
# model_settings    = list(labels = labels_use),  # set labels
options           = list(seed = 123)
)
save(out, file = "outputs/models/acled_keyatm_base_02_04_susbet.RData")
## diagnostics
plot_topicprop(out, show_topic = 1:7)
fig_modelfit <- plot_modelfit(out)
fig_modelfit
plot_alpha(out)
plot_pi(out)
acled_with_preds = out$theta %>%
as.data.frame() %>%
cbind(acled) %>%
pivot_longer(cols = `1_cultural`:`8_war (pro)`, names_to = "topic", values_to = "proportion") %>%
group_by(event_id_cnty) %>%
mutate(max = proportion == max(proportion)) %>%
filter(max) %>%
mutate(protest_type = str_extract(topic, "(?<=_).+")) %>%
mutate(protest_type = factor(protest_type, levels = c('environmental', 'cultural',
'political', 'social',
'economic', 'legal',
'war (anti)', 'war (pro)')))
new_subset <- acled_with_preds %>%
filter(!is.na(topic_manual))
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$topic_manual <- as.factor(new_subset$topic_manual)
levels(new_subset$protest_type)
unique(new_subset$protest_type)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$topic_manual)
print(conf_matrix)
##### load and preprocess data #####
acled <- import("data/processed_data/acled_merged_18_23_edited_MT.csv")
unique(acled$event_id_cnty)
acled_with_type = acled %>% filter(!is.na(topic_manual))
#### Yana's code to get top freq words per category ####
#create corpus object
corp_acled = corpus(acled,
docid_field = "event_id_cnty",
text_field = "notes")
# tokenize texts
toks_acled = tokens(corp_acled, remove_punct = TRUE, remove_number = TRUE) %>%
tokens_remove(pattern = c(stopwords("en"), "protest*", "size", "=")) %>%
tokens_wordstem() # stem the keywords to make it easeir to use later
dfmt_acled = dfm(toks_acled) %>%
dfm_trim(max_termfreq = 0.80, termfreq_type = "prop") #filter out most common words
#generate testing data
set.seed(123)
test_ids = acled_with_type %>%
group_by(topic_manual) %>%
sample_frac(0.3) %>%
pull(event_id_cnty)
acled_with_labels = acled %>%
left_join(acled_with_type %>% select(event_id_cnty, topic_manual)) %>%
mutate(label = as.factor(ifelse(event_id_cnty %in% test_ids, NA, topic_manual))
%>% as.numeric())
#generate labels (with NAs for testing data)
acled_train <- acled %>% filter(!(event_id_cnty %in% test_ids))
#generate labels (with NAs for testing data)
acled_train <- acled %>% filter(!(event_id_cnty %in% test_ids))
corp_train = corpus(acled_train,
docid_field = "event_id_cnty",
text_field = "notes")
# tokenize texts
toks_acled_tr = tokens(corp_train, remove_punct = TRUE, remove_number = TRUE) %>%
tokens_remove(pattern = c(stopwords("en"), "protest*", "size", "=")) %>%
tokens_wordstem() # stem the keywords to make it easeir to use later
dfmt_acled_tr = dfm(toks_acled_tr) %>%
dfm_trim(max_termfreq = 0.80, termfreq_type = "prop") #filter out most common words
#get top 75 features for each category
top_words = topfeatures(dfmt_acled_tr, n = 75, groups = dfmt_acled_tr$topic_manual)
#make a data frame with top words for all categories
top_words_df = top_words %>% bind_cols()
all_values = data.frame(value = unlist(top_words),
name = names(unlist(top_words))) %>%
separate(name, c("type", "token"), "\\.") %>%
group_by(token) %>%
filter(n() == 1)  # this is to remove tokens that appear in more than one category -
# to make classification easier later, we need unique tokens
# Group by 'type' and then create a list of 'token' for each 'type'
keywords <- all_values %>%
group_by(type) %>%
summarise(words = list(token), .groups = 'drop') %>%
deframe() %>% # Converts the dataframe to a named list
map(~ unlist(.x)) # To ensure each element is a vector of words rather than a list
keyATM_docs <- keyATM_read(texts = dfmt_acled)
summary(keyATM_docs)
# Fit keyatm with labels
out <- keyATM(
docs              = keyATM_docs,    # text input
no_keyword_topics = 0,              # number of topics without keyword
keywords          = keywords,       # keywords
model             = "base",         # select the model
# model_settings    = list(labels = labels_use),  # set labels
options           = list(seed = 123)
)
save(out, file = "outputs/models/acled_keyatm_base_02_04_susbet.RData")
## diagnostics
plot_topicprop(out, show_topic = 1:7)
acled_with_preds = out$theta %>%
as.data.frame() %>%
cbind(acled) %>%
pivot_longer(cols = `1_cultural`:`8_war (pro)`, names_to = "topic", values_to = "proportion") %>%
group_by(event_id_cnty) %>%
mutate(max = proportion == max(proportion)) %>%
filter(max) %>%
mutate(protest_type = str_extract(topic, "(?<=_).+")) %>%
mutate(protest_type = factor(protest_type, levels = c('environmental', 'cultural',
'political', 'social',
'economic', 'legal',
'war (anti)', 'war (pro)')))
#### quality labels check #####
new_subset <- acled_with_preds %>%
filter(!is.na(topic_manual))
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$topic_manual <- as.factor(new_subset$topic_manual)
levels(new_subset$protest_type)
unique(new_subset$protest_type)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$topic_manual)
print(conf_matrix)
new_subset <- acled_with_preds %>%
filter(event_id_cnty %in% test_ids)
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$topic_manual <- as.factor(new_subset$topic_manual)
levels(new_subset$protest_type)
unique(new_subset$protest_type)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$topic_manual)
print(conf_matrix)
new_subset <- acled_with_preds %>%
# filter(event_id_cnty %in% test_ids)
filter(!is.na(topic_manual))
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$topic_manual <- as.factor(new_subset$topic_manual)
levels(new_subset$protest_type)
unique(new_subset$protest_type)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$protest_type, new_subset$topic_manual)
print(conf_matrix)
View(acled)
new_subset <- acled_with_preds %>%
# filter(event_id_cnty %in% test_ids)
filter(!is.na(pro_regime))
new_subset$pro_kremlin_indicator <- as.factor(new_subset$pro_kremlin_indicator)
new_subset$pro_regime <- as.factor(new_subset$pro_regime)
levels(new_subset$pro_kremlin_indicator)
unique(new_subset$pro_kremlin_indicator)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$pro_kremlin_indicator, new_subset$pro_regime)
print(conf_matrix)
new_subset <- acled_with_preds %>%
# filter(event_id_cnty %in% test_ids)
filter(!is.na(pro_regime))
new_subset$pro_kremlin_indicator <- as.factor(new_subset$pro_kremlin_indicator)
new_subset$pro_regime <- as.factor(new_subset$pro_regime)
levels(new_subset$pro_kremlin_indicator)
unique(new_subset$pro_kremlin_indicator)
# Confusion Matrix
conf_matrix <- confusionMatrix(new_subset$pro_kremlin_indicator, new_subset$pro_regime)
print(conf_matrix)
?confusionMatrix
##### load and preprocess data #####
acled <- import("data/processed_data/acled_merged_18_23_edited_MT.csv")
unique(acled$event_id_cnty)
acled_with_type = acled %>% filter(!is.na(topic_manual))
#### Yana's code to get top freq words per category ####
#create corpus object
corp_acled = corpus(acled,
docid_field = "event_id_cnty",
text_field = "notes")
# tokenize texts
toks_acled = tokens(corp_acled, remove_punct = TRUE, remove_number = TRUE) %>%
tokens_remove(pattern = c(stopwords("en"), "protest*", "size", "=")) %>%
tokens_wordstem() # stem the keywords to make it easeir to use later
dfmt_acled = dfm(toks_acled) %>%
dfm_trim(max_termfreq = 0.80, termfreq_type = "prop") #filter out most common words
# #generate testing data
# set.seed(123)
# test_ids = acled_with_type %>%
#   group_by(topic_manual) %>%
#   sample_frac(0.3) %>%
#   pull(event_id_cnty)
#
#
# #generate labels (with NAs for testing data)
# acled_train <- acled %>% filter(!(event_id_cnty %in% test_ids))
#
# corp_train = corpus(acled_train,
#                     docid_field = "event_id_cnty",
#                     text_field = "notes")
# # tokenize texts
# toks_acled_tr = tokens(corp_train, remove_punct = TRUE, remove_number = TRUE) %>%
#   tokens_remove(pattern = c(stopwords("en"), "protest*", "size", "=")) %>%
#   tokens_wordstem() # stem the keywords to make it easeir to use later
#
# dfmt_acled_tr = dfm(toks_acled_tr) %>%
#   dfm_trim(max_termfreq = 0.80, termfreq_type = "prop") #filter out most common words
#get top 75 features for each category
top_words = topfeatures(dfmt_acled, n = 75, groups = dfmt_acled$topic_manual)
#make a data frame with top words for all categories
top_words_df = top_words %>% bind_cols()
all_values = data.frame(value = unlist(top_words),
name = names(unlist(top_words))) %>%
separate(name, c("type", "token"), "\\.") %>%
group_by(token) %>%
filter(n() == 1)  # this is to remove tokens that appear in more than one category -
# to make classification easier later, we need unique tokens
# Group by 'type' and then create a list of 'token' for each 'type'
keywords <- all_values %>%
group_by(type) %>%
summarise(words = list(token), .groups = 'drop') %>%
deframe() %>% # Converts the dataframe to a named list
map(~ unlist(.x)) # To ensure each element is a vector of words rather than a list
keyATM_docs <- keyATM_read(texts = dfmt_acled)
summary(keyATM_docs)
# save(out, file = "outputs/models/acled_keyatm_base_02_04_susbet.RData")
load("outputs/acled_keyatm_base_02_04.RData")
# save(out, file = "outputs/models/acled_keyatm_base_02_04_susbet.RData")
load("outputs/models/acled_keyatm_base_02_04.RData")
acled_with_preds = out$theta %>%
as.data.frame() %>%
cbind(acled) %>%
pivot_longer(cols = `1_cultural`:`8_war (pro)`, names_to = "topic", values_to = "proportion") %>%
group_by(event_id_cnty) %>%
mutate(max = proportion == max(proportion)) %>%
filter(max) %>%
mutate(protest_type = str_extract(topic, "(?<=_).+")) %>%
mutate(protest_type = factor(protest_type, levels = c('environmental', 'cultural',
'political', 'social',
'economic', 'legal',
'war (anti)', 'war (pro)')))
fig_modelfit <- plot_modelfit(out)
fig_modelfit
plot_topicprop(out, show_topic = 1:7)
acled_with_preds = out$theta %>%
as.data.frame() %>%
cbind(acled) %>%
pivot_longer(cols = `1_cultural`:`8_war (pro)`, names_to = "topic", values_to = "proportion") %>%
group_by(event_id_cnty) %>%
mutate(max = proportion == max(proportion)) %>%
filter(max) %>%
mutate(protest_type = str_extract(topic, "(?<=_).+")) %>%
mutate(protest_type = factor(protest_type, levels = c('environmental', 'cultural',
'political', 'social',
'economic', 'legal',
'war (anti)', 'war (pro)')))
#### quality labels check #####
new_subset <- acled_with_preds %>%
# filter(event_id_cnty %in% test_ids)
filter(!is.na(topic_manual))
new_subset$protest_type <- as.factor(new_subset$protest_type)
new_subset$topic_manual <- as.factor(new_subset$topic_manual)
levels(new_subset$protest_type)
unique(new_subset$protest_type)
# Confusion Matrix
conf_matrix_protest_type <- confusionMatrix(new_subset$protest_type, new_subset$topic_manual)
print(conf_matrix_protest_type)
##### Check on pro-regime #####
new_subset <- acled_with_preds %>%
# filter(event_id_cnty %in% test_ids)
filter(!is.na(pro_regime))
new_subset$pro_kremlin_indicator <- as.factor(new_subset$pro_kremlin_indicator)
new_subset$pro_regime <- as.factor(new_subset$pro_regime)
levels(new_subset$pro_kremlin_indicator)
unique(new_subset$pro_kremlin_indicator)
# Confusion Matrix
conf_matrix_regime <- confusionMatrix(new_subset$pro_kremlin_indicator, new_subset$pro_regime)
print(conf_matrix_regime)
# save env for RMD report
save.image(file = "outputs/keyatm_env.RData")
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, rio, ggplot2, lubridate, quanteda, keyATM, readxl, caret)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, rio, ggplot2, lubridate, quanteda, keyATM, readxl, caret)
# setwd(".../nonviolent-repression")
load("outputs/keyatm_env.RData")
setwd("C:/Users/murrn/GitHub/nonviolent-repression")
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, rio, ggplot2, lubridate, quanteda, keyATM, readxl, caret)
setwd("C:/Users/murrn/GitHub/nonviolent-repression")
load("outputs/keyatm_env.RData")
load("outputs/keyatm_env.RData")
load("outputs/keyatm_env.RData")
load("outputs/keyatm_env.RData")
load("outputs/keyatm_env.RData")
load("outputs/keyatm_env.RData")
setwd("C:/Users/murrn/GitHub/nonviolent-repression")
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, rio, ggplot2, lubridate, quanteda, keyATM, readxl, caret)
load("outputs/keyatm_env.RData")
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, rio, ggplot2, lubridate, quanteda, keyATM, readxl, caret)
load("outputs/keyatm_env.RData")
load("outputs/keyatm_env.RData")
print(conf_matrix_regime)
print(conf_matrix_protest_type)
print(conf_matrix_protest_type)
```{r echo=FALSE}
print(conf_matrix_protest_type)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, rio, ggplot2, lubridate, quanteda, keyATM, readxl, caret)
# Function to convert confusion matrix to Markdown format
convertConfMatrixToMarkdown <- function(conf_matrix) {
# Extracting the table
matrix <- conf_matrix$table
# Starting the markdown string with the table header
md <- "| Prediction \\ Reference | "
md <- paste(md, paste(colnames(matrix), collapse = " | "), " |\n", sep = "")
# Adding separator
md <- paste(md, "|------------------------|", paste(rep("-----", ncol(matrix)), collapse = "|"), "|\n", sep = "")
# Adding rows of the table
for (i in 1:nrow(matrix)) {
md <- paste(md, "| ", rownames(matrix)[i], " | ", paste(matrix[i, ], collapse = " | "), " |\n", sep = "")
}
# Adding statistics
stats <- c(
paste("Accuracy: ", round(conf_matrix$overall['Accuracy'], 2)),
paste("95% CI: ", paste("(", paste(conf_matrix$overall['AccuracyLower'], conf_matrix$overall['AccuracyUpper'], sep = ", "), ")", sep = "")),
paste("Kappa: ", round(conf_matrix$overall['Kappa'], 2)),
paste("Sensitivity: ", round(conf_matrix$byClass['Sensitivity'], 2)),
paste("Specificity: ", round(conf_matrix$byClass['Specificity'], 2)),
paste("Pos Pred Value: ", round(conf_matrix$byClass['Pos Pred Value'], 2)),
paste("Neg Pred Value: ", round(conf_matrix$byClass['Neg Pred Value'], 2)),
paste("Prevalence: ", round(conf_matrix$byClass['Prevalence'], 2)),
paste("Detection Rate: ", round(conf_matrix$byClass['Detection Rate'], 2)),
paste("Detection Prevalence: ", round(conf_matrix$byClass['Detection Prevalence'], 2)),
paste("Balanced Accuracy: ", round(conf_matrix$byClass['Balanced Accuracy'], 2))
)
md <- paste(md, "\n## Statistics\n", sep = "")
# Adding each statistic in a list format
for (stat in stats) {
md <- paste(md, "- ", stat, "\n", sep = "")
}
return(md)
}
markdownText <- convertConfMatrixToMarkdown(conf_matrix_regime)
cat(markdownText)
markdownText <- convertConfMatrixToMarkdown(conf_matrix_protest_type)
cat(markdownText)
markdownText <- convertConfMatrixToMarkdown(conf_matrix_regime)
markdownText
conf_matrix_protest_type$byClass
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, rio, ggplot2, lubridate, quanteda, keyATM, readxl, caret)
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_protest_type$byClass, format = "markdown")
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(knitr, tidyverse, rio, ggplot2, lubridate, quanteda, keyATM, readxl, caret)
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_protest_type$byClass, format = "markdown")
# Print the Markdown table
markdown_table
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_regime$table, format = "markdown")
# Print the Markdown table
markdown_table
conf_matrix_regime$overall
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_regime$overall, format = "markdown")
# Print the Markdown table
markdown_table
conf_matrix_regime$positive
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_regime$overall, format = "markdown")
# Print the Markdown table
markdown_table
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_regime$table, format = "markdown")
# Print the Markdown table
markdown_table
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_protest_type$table, format = "markdown")
# Print the Markdown table
markdown_table
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_protest_type$overall, format = "markdown")
# Print the Markdown table
markdown_table
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_protest_type$byClass, format = "markdown")
# Print the Markdown table
markdown_table
markdown_table
conf_matrix_protest_type$byClass
data.frame(conf_matrix_protest_type$byClass)
x = data.frame(conf_matrix_protest_type$byClass)
View(x)
kable(x)
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_protest_type$byClass, format = "markdown", digits = 2)
# Print the Markdown table
markdown_table
# Convert the summarized data to a Markdown table
markdown_table <- kable(conf_matrix_regime$overall, format = "markdown", digits = 2)
# Print the Markdown table
markdown_table
# Convert the summarized data to a Markdown table
df = data.frame(conf_matrix_protest_type$byClass) %>%
select(-c("Neg.Pred.Value", "Pos.Pred.Value"))
markdown_table <- kable(df, format = "markdown", digits = 2)
# Print the Markdown table
markdown_table
# Convert the summarized data to a Markdown table
df = data.frame(conf_matrix_protest_type$byClass) %>%
select(-c("Neg.Pred.Value", "Pos.Pred.Value",
"Prevalence" ,"Detection.Prevalence"))
markdown_table <- kable(df, format = "markdown", digits = 2)
# Print the Markdown table
markdown_table
# Convert the summarized data to a Markdown table
df = data.frame(conf_matrix_protest_type$byClass) %>%
select(-c("Neg.Pred.Value", "Pos.Pred.Value",
"Prevalence" ,"Detection.Prevalence" ,"Detection.Prevalence"))
markdown_table <- kable(df, format = "markdown", digits = 2)
# Print the Markdown table
markdown_table
acled_with_preds <- acled_with_preds %>%
mutate(date = dmy(event_date),
month_year = format(date, "%Y-%m"))
unique_counts_polit <- acled_with_preds %>%
mutate(month_year = as.Date(paste0(month_year, "-01"))) %>%
group_by(month_year, protest_type) %>%
summarise(unique_notes = n_distinct(notes))
acled_with_preds <- acled_with_preds %>%
mutate(date = dmy(event_date),
month_year = format(date, "%Y-%m"))
unique_counts_polit <- acled_with_preds %>%
mutate(month_year = as.Date(paste0(month_year, "-01"))) %>%
group_by(month_year, protest_type) %>%
summarise(unique_notes = n_distinct(notes))
# Plotting
political_protests_plot <- ggplot(unique_counts_polit, aes(x = month_year, y = unique_notes, color = protest_type)) +
geom_line() +
geom_point() +
scale_x_date(date_breaks = "1 year", date_labels = "%Y", minor_breaks = "1 month") +
labs(title = "Monthly Number of Unique Protests in Russia",
x = "",
y = "Number of Unique Protests",
linetype = "") +  # Set legend title to no title
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
geom_vline(xintercept = as.Date("2022-02-24"), linetype = "dashed", color = "red")
unique_counts_polit <- acled_with_preds %>%
mutate(month_year = as.Date(paste0(month_year, "-01"))) %>%
group_by(month_year, protest_type) %>%
summarise(unique_notes = n_distinct(notes))
# Plotting
political_protests_plot <- ggplot(unique_counts_polit, aes(x = month_year, y = unique_notes, color = protest_type)) +
geom_line() +
geom_point() +
scale_x_date(date_breaks = "1 year", date_labels = "%Y", minor_breaks = "1 month") +
labs(title = "Monthly Number of Unique Protests in Russia",
x = "",
y = "Number of Unique Protests",
linetype = "") +  # Set legend title to no title
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
geom_vline(xintercept = as.Date("2022-02-24"), linetype = "dashed", color = "red")
political_protests_plot
# Calculating the share of each protest type per month
unique_counts_polit <- acled_with_preds %>%
mutate(month_year = as.Date(paste0(month_year, "-01"))) %>%
group_by(month_year, protest_type) %>%
summarise(unique_notes = n_distinct(notes), .groups = 'drop') %>%
# Calculate total protests per month across all types
group_by(month_year) %>%
mutate(total_notes = sum(unique_notes)) %>%
# Calculate the share of protests for each type
mutate(share_of_protests = unique_notes / total_notes) %>%
# Select only necessary columns
select(month_year, protest_type, share_of_protests)
# Plotting the shares
political_protests_plot <- ggplot(unique_counts_polit, aes(x = month_year, y = share_of_protests, color = protest_type)) +
geom_line() +
geom_point() +
scale_x_date(date_breaks = "1 year", date_labels = "%Y", minor_breaks = "1 month") +
labs(title = "Monthly Share of Protests by Type in Russia",
x = "",
y = "Share of Total Protests",
color = "Protest Type") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
geom_vline(xintercept = as.Date("2022-02-24"), linetype = "dashed", color = "red")
# Display the plot
print(political_protests_plot)
unique_counts_polit
